"""Smart Template System with Auto-GenerationLearns from successful workflows to create templates"""import jsonimport loggingimport refrom collections import Counterfrom dataclasses import dataclassfrom datetime import datetimefrom pathlib import Pathfrom typing import Anyimport yaml# Note: jinja2 dependency would need to be added to requirementstry:    from jinja2 import Environment, FileSystemLoader, Template    JINJA2_AVAILABLE = Trueexcept ImportError:    JINJA2_AVAILABLE = False    Environment = None    FileSystemLoader = None    Template = Nonelogger = logging.getLogger(__name__)@dataclassclass WorkflowPattern:    """Represents a pattern found in successful workflows."""    pattern_type: str    frequency: int    confidence: float    data: dict[str, Any]@dataclassclass TemplateIntent:    """Represents the analyzed intent of a template request."""    type: str    technologies: list[str]    file_types: list[str]    complexity: str    operations: list[str]    confidence: floatclass WorkflowAnalyzer:    """Analyzes successful workflows to extract patterns."""    def __init__(self, artifacts_dir: str = "artifacts"):        self.artifacts_dir = Path(artifacts_dir)        self.patterns_cache: dict[str, list[WorkflowPattern]] = {}    def analyze_successful_workflows(self) -> dict[str, list[WorkflowPattern]]:        """Analyze patterns from successful workflow executions."""        if self.patterns_cache:            return self.patterns_cache        raw_patterns = {            "tool_sequences": [],            "file_patterns": [],            "cost_efficiency": [],            "success_factors": [],            "step_dependencies": [],        }        successful_workflows = self._load_successful_workflows()        logger.info(f"Analyzing {len(successful_workflows)} successful workflows")        # Extract raw patterns        for workflow in successful_workflows:            self._extract_patterns_from_workflow(workflow, raw_patterns)        # Convert to structured patterns        patterns = self._consolidate_patterns(raw_patterns)        self.patterns_cache = patterns        return patterns    def _load_successful_workflows(self) -> list[dict[str, Any]]:        """Load successful workflow executions from artifacts."""        successful_workflows = []        if not self.artifacts_dir.exists():            logger.warning(f"Artifacts directory does not exist: {self.artifacts_dir}")            return successful_workflows        # Scan artifact files        for artifact_file in self.artifacts_dir.glob("**/*.json"):            try:                with open(artifact_file, encoding="utf-8") as f:                    data = json.load(f)                # Check if workflow was successful                if (                    data.get("status") == "success"                    or data.get("success") is True                    or (                        isinstance(data.get("failed"), list)                        and len(data["failed"]) == 0                    )                ):                    successful_workflows.append(data)            except Exception as e:                logger.warning(f"Failed to load artifact {artifact_file}: {e}")                continue        return successful_workflows    def _extract_patterns_from_workflow(        self, workflow_data: dict[str, Any], patterns: dict[str, list]    ):        """Extract patterns from a single successful workflow."""        # Tool sequences        tools = []        steps = workflow_data.get("steps", workflow_data.get("nodes", []))        for step in steps:            tool = step.get("tool", step.get("actor"))            if tool:                tools.append(tool)        if len(tools) > 1:            patterns["tool_sequences"].append(tools)        # File patterns        files_changed = workflow_data.get(            "files_changed", workflow_data.get("modified_files", [])        )        if files_changed:            patterns["file_patterns"].extend(files_changed)        # Cost efficiency        cost = workflow_data.get("total_cost", workflow_data.get("cost", 0))        duration = workflow_data.get(            "duration_seconds", workflow_data.get("execution_time", 0)        )        if cost > 0 and duration > 0:            efficiency = duration / cost  # seconds per dollar            patterns["cost_efficiency"].append(                {                    "tools": tools,                    "efficiency": efficiency,                    "cost": cost,                    "duration": duration,                }            )        # Success factors        if workflow_data.get("success_rate", 1.0) > 0.8:            patterns["success_factors"].append(                {                    "tools": tools,                    "file_types": self._extract_file_types(files_changed),                    "complexity": self._estimate_complexity(workflow_data),                }            )        # Step dependencies        for step in steps:            deps = step.get("dependencies", step.get("depends_on", []))            if deps:                patterns["step_dependencies"].append(                    {                        "step": step.get("id", step.get("name")),                        "tool": step.get("tool", step.get("actor")),                        "dependencies": deps,                    }                )    def _extract_file_types(self, files: list[str]) -> list[str]:        """Extract file types from file paths."""        file_types = []        for file_path in files:            suffix = Path(file_path).suffix            if suffix:                file_types.append(suffix)        return file_types    def _estimate_complexity(self, workflow_data: dict[str, Any]) -> str:        """Estimate workflow complexity based on metrics."""        steps_count = len(workflow_data.get("steps", workflow_data.get("nodes", [])))        duration = workflow_data.get("duration_seconds", 0)        workflow_data.get("total_cost", 0)        if steps_count <= 3 and duration < 300:  # < 5 minutes            return "simple"        elif steps_count <= 6 and duration < 1800:  # < 30 minutes            return "medium"        else:            return "complex"    def _consolidate_patterns(        self, raw_patterns: dict[str, list]    ) -> dict[str, list[WorkflowPattern]]:        """Consolidate raw patterns into structured pattern objects."""        consolidated = {}        # Tool sequences        tool_seq_counter = Counter()        for seq in raw_patterns["tool_sequences"]:            if len(seq) >= 2:                # Create pairs and triplets                for i in range(len(seq) - 1):                    pair = tuple(seq[i : i + 2])                    tool_seq_counter[pair] += 1        tool_patterns = []        for seq, count in tool_seq_counter.most_common(10):            confidence = min(1.0, count / len(raw_patterns["tool_sequences"]))            tool_patterns.append(                WorkflowPattern(                    pattern_type="tool_sequence",                    frequency=count,                    confidence=confidence,                    data={"sequence": list(seq)},                )            )        consolidated["tool_sequences"] = tool_patterns        # File patterns        file_counter = Counter()        for file_path in raw_patterns["file_patterns"]:            file_ext = Path(file_path).suffix            if file_ext:                file_counter[file_ext] += 1        file_patterns = []        total_files = len(raw_patterns["file_patterns"])        for ext, count in file_counter.most_common(10):            confidence = count / total_files if total_files > 0 else 0            file_patterns.append(                WorkflowPattern(                    pattern_type="file_extension",                    frequency=count,                    confidence=confidence,                    data={"extension": ext},                )            )        consolidated["file_patterns"] = file_patterns        # Cost efficiency patterns        efficiency_patterns = []        if raw_patterns["cost_efficiency"]:            # Sort by efficiency (higher is better)            sorted_efficiency = sorted(                raw_patterns["cost_efficiency"],                key=lambda x: x["efficiency"],                reverse=True,            )            for i, item in enumerate(sorted_efficiency[:5]):  # Top 5                confidence = 1.0 - (i * 0.1)  # Decreasing confidence                efficiency_patterns.append(                    WorkflowPattern(                        pattern_type="cost_efficiency",                        frequency=1,                        confidence=confidence,                        data=item,                    )                )        consolidated["cost_efficiency"] = efficiency_patterns        return consolidatedclass SmartTemplateGenerator:    """Generates workflow templates from patterns and user intent."""    def __init__(self, templates_dir: str = ".ai/workflows/templates"):        self.templates_dir = Path(templates_dir)        self.templates_dir.mkdir(parents=True, exist_ok=True)        if JINJA2_AVAILABLE:            self.env = Environment(loader=FileSystemLoader(str(self.templates_dir)))        else:            self.env = None            logger.warning("Jinja2 not available - template rendering disabled")        self.analyzer = WorkflowAnalyzer()    async def generate_template_from_request(        self, request: str, template_name: str = None    ) -> dict[str, Any]:        """Generate a workflow template from natural language request."""        # Analyze request intent        intent = self._analyze_request_intent(request)        logger.info(            f"Analyzed intent: {intent.type} with confidence {intent.confidence}"        )        # Get relevant patterns        patterns = self.analyzer.analyze_successful_workflows()        # Generate template        template = self._create_template_from_intent(intent, patterns)        # Set template name        if not template_name:            template_name = (                f"auto_{intent.type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"            )        template["name"] = template_name        # Save template        template_path = self._save_template(template, template_name)        return {            "template_path": str(template_path),            "template": template,            "intent": intent,            "patterns_used": len(patterns),        }    def _analyze_request_intent(self, request: str) -> TemplateIntent:        """Extract intent from natural language request."""        request_lower = request.lower()        # Initialize intent        intent_type = "unknown"        technologies = []        file_types = []        complexity = "medium"        operations = []        confidence = 0.5        # Detect intent type with confidence scoring        type_patterns = {            "bugfix": (["fix", "bug", "error", "issue", "resolve", "debug"], 0.9),            "feature": (["add", "implement", "create", "new", "build", "develop"], 0.8),            "testing": (["test", "verify", "validate", "check", "ensure"], 0.9),            "refactor": (                ["refactor", "cleanup", "optimize", "improve", "reorganize"],                0.8,            ),            "documentation": (                ["document", "docs", "readme", "comment", "explain"],                0.9,            ),            "deployment": (["deploy", "release", "publish", "ship"], 0.9),            "analysis": (["analyze", "review", "audit", "assess", "evaluate"], 0.8),        }        best_type_score = 0        for type_name, (keywords, base_confidence) in type_patterns.items():            score = sum(1 for keyword in keywords if keyword in request_lower)            if score > best_type_score:                best_type_score = score                intent_type = type_name                confidence = min(0.95, base_confidence * (score / len(keywords)))        # Detect technologies        tech_patterns = {            "python": ["python", "py", "django", "flask", "fastapi", "pip"],            "javascript": ["js", "javascript", "node", "react", "vue", "npm"],            "typescript": ["ts", "typescript"],            "golang": ["go", "golang"],            "rust": ["rust", "cargo"],            "java": ["java", "spring", "maven", "gradle"],            "database": ["sql", "postgres", "mysql", "database", "db", "sqlite"],            "api": ["api", "rest", "graphql", "endpoint", "service"],            "web": ["web", "html", "css", "frontend", "backend"],            "cloud": ["aws", "azure", "gcp", "cloud", "kubernetes", "docker"],            "security": ["security", "auth", "oauth", "encrypt", "secure"],        }        for tech, keywords in tech_patterns.items():            if any(keyword in request_lower for keyword in keywords):                technologies.append(tech)        # Detect operations        operation_patterns = {            "create": ["create", "add", "implement", "build", "generate"],            "modify": ["modify", "update", "change", "edit", "alter"],            "delete": ["delete", "remove", "cleanup", "purge"],            "test": ["test", "verify", "validate", "check"],            "analyze": ["analyze", "review", "audit", "inspect"],        }        for operation, keywords in operation_patterns.items():            if any(keyword in request_lower for keyword in keywords):                operations.append(operation)        # Estimate complexity        complexity_indicators = {            "simple": ["simple", "quick", "basic", "minimal"],            "complex": ["complex", "advanced", "comprehensive", "full", "complete"],            "enterprise": ["enterprise", "production", "scalable", "distributed"],        }        for level, keywords in complexity_indicators.items():            if any(keyword in request_lower for keyword in keywords):                complexity = level                break        # Detect file types from context        file_extensions = re.findall(r"\.(\w+)", request)        file_types.extend(file_extensions)        return TemplateIntent(            type=intent_type,            technologies=technologies,            file_types=file_types,            complexity=complexity,            operations=operations,            confidence=confidence,        )    def _create_template_from_intent(        self, intent: TemplateIntent, patterns: dict[str, list[WorkflowPattern]]    ) -> dict[str, Any]:        """Create workflow template based on intent and patterns."""        # Base template structure        template = {            "name": f"auto_generated_{intent.type}",            "description": f"Auto-generated template for {intent.type} workflows",            "metadata": {                "generated_at": datetime.utcnow().isoformat(),                "intent_confidence": intent.confidence,                "technologies": intent.technologies,                "complexity": intent.complexity,            },            "inputs": {                "files": {                    "description": "Files to process",                    "default": "{{ default_files }}",                },                "lane": {                    "description": "Development lane",                    "default": "{{ default_lane }}",                },            },            "policy": {                "max_tokens": self._get_token_budget_for_complexity(intent.complexity),                "prefer_deterministic": True,            },            "steps": [],        }        # Generate steps based on intent type        if intent.type == "bugfix":            template["steps"] = self._create_bugfix_steps(intent, patterns)        elif intent.type == "feature":            template["steps"] = self._create_feature_steps(intent, patterns)        elif intent.type == "testing":            template["steps"] = self._create_testing_steps(intent, patterns)        elif intent.type == "refactor":            template["steps"] = self._create_refactor_steps(intent, patterns)        elif intent.type == "documentation":            template["steps"] = self._create_documentation_steps(intent, patterns)        elif intent.type == "analysis":            template["steps"] = self._create_analysis_steps(intent, patterns)        else:            template["steps"] = self._create_generic_steps(intent, patterns)        # Add technology-specific optimizations        self._optimize_for_technologies(template, intent.technologies)        return template    def _create_bugfix_steps(        self, intent: TemplateIntent, patterns: dict[str, list[WorkflowPattern]]    ) -> list[dict[str, Any]]:        """Create steps for bugfix workflows."""        return [            {                "id": "1.001",                "name": "Analyze Issue",                "actor": "vscode_diagnostics",                "with": {                    "analyzers": self._get_analyzers_for_tech(intent.technologies),                    "focus": "errors",                },                "emits": ["artifacts/diagnostics.json"],            },            {                "id": "1.002",                "name": "Investigate Bug",                "actor": "ai_editor",                "with": {                    "goal": "Analyze the bug and identify root cause",                    "files": "{{ inputs.files }}",                    "context": "bugfix investigation",                },                "depends_on": ["1.001"],                "emits": ["artifacts/bug_analysis.json"],            },            {                "id": "1.003",                "name": "Implement Fix",                "actor": "ai_editor",                "with": {                    "goal": "Implement the bug fix based on analysis",                    "files": "{{ inputs.files }}",                    "context": "bug fix implementation",                },                "depends_on": ["1.002"],                "emits": ["artifacts/fix_implementation.json"],            },            {                "id": "1.004",                "name": "Verify Fix",                "actor": "pytest_runner",                "with": {                    "test_pattern": "{{ test_pattern | default('tests/') }}",                    "coverage": True,                },                "depends_on": ["1.003"],                "emits": ["artifacts/test_results.json"],            },        ]    def _create_feature_steps(        self, intent: TemplateIntent, patterns: dict[str, list[WorkflowPattern]]    ) -> list[dict[str, Any]]:        """Create steps for feature development workflows."""        return [            {                "id": "1.001",                "name": "Design Feature",                "actor": "ai_editor",                "with": {                    "goal": "Design feature architecture and implementation plan",                    "files": "{{ inputs.files }}",                    "context": "feature design",                },                "emits": ["artifacts/feature_design.json"],            },            {                "id": "1.002",                "name": "Implement Core",                "actor": "ai_editor",                "with": {                    "goal": "Implement core feature functionality",                    "files": "{{ inputs.files }}",                    "context": "feature implementation",                },                "depends_on": ["1.001"],                "emits": ["artifacts/core_implementation.json"],            },            {                "id": "1.003",                "name": "Add Tests",                "actor": "ai_editor",                "with": {                    "goal": "Add comprehensive tests for new feature",                    "files": "tests/",                    "context": "test implementation",                },                "depends_on": ["1.002"],                "emits": ["artifacts/test_implementation.json"],            },            {                "id": "1.004",                "name": "Run Tests",                "actor": "pytest_runner",                "with": {"test_pattern": "tests/", "coverage": True},                "depends_on": ["1.003"],                "emits": ["artifacts/test_results.json"],            },        ]    def _create_testing_steps(        self, intent: TemplateIntent, patterns: dict[str, list[WorkflowPattern]]    ) -> list[dict[str, Any]]:        """Create steps for testing workflows."""        return [            {                "id": "1.001",                "name": "Analyze Code Coverage",                "actor": "pytest_runner",                "with": {                    "test_pattern": "tests/",                    "coverage": True,                    "coverage_report": True,                },                "emits": ["artifacts/coverage_report.json"],            },            {                "id": "1.002",                "name": "Generate Missing Tests",                "actor": "ai_editor",                "with": {                    "goal": "Generate tests for uncovered code paths",                    "files": "{{ inputs.files }}",                    "context": "test generation",                },                "depends_on": ["1.001"],                "emits": ["artifacts/generated_tests.json"],            },            {                "id": "1.003",                "name": "Validate Tests",                "actor": "pytest_runner",                "with": {"test_pattern": "tests/", "coverage": True},                "depends_on": ["1.002"],                "emits": ["artifacts/final_test_results.json"],            },        ]    def _create_refactor_steps(        self, intent: TemplateIntent, patterns: dict[str, list[WorkflowPattern]]    ) -> list[dict[str, Any]]:        """Create steps for refactoring workflows."""        return [            {                "id": "1.001",                "name": "Code Analysis",                "actor": "vscode_diagnostics",                "with": {                    "analyzers": self._get_analyzers_for_tech(intent.technologies),                    "focus": "quality",                },                "emits": ["artifacts/code_analysis.json"],            },            {                "id": "1.002",                "name": "Refactor Code",                "actor": "ai_editor",                "with": {                    "goal": "Refactor code to improve quality and maintainability",                    "files": "{{ inputs.files }}",                    "context": "code refactoring",                },                "depends_on": ["1.001"],                "emits": ["artifacts/refactored_code.json"],            },            {                "id": "1.003",                "name": "Verify Refactoring",                "actor": "pytest_runner",                "with": {"test_pattern": "tests/", "coverage": True},                "depends_on": ["1.002"],                "emits": ["artifacts/refactor_verification.json"],            },        ]    def _create_documentation_steps(        self, intent: TemplateIntent, patterns: dict[str, list[WorkflowPattern]]    ) -> list[dict[str, Any]]:        """Create steps for documentation workflows."""        return [            {                "id": "1.001",                "name": "Analyze Code Structure",                "actor": "vscode_diagnostics",                "with": {                    "analyzers": ["structure", "exports"],                    "focus": "documentation",                },                "emits": ["artifacts/code_structure.json"],            },            {                "id": "1.002",                "name": "Generate Documentation",                "actor": "ai_editor",                "with": {                    "goal": "Generate comprehensive documentation",                    "files": "{{ inputs.files }}",                    "context": "documentation generation",                },                "depends_on": ["1.001"],                "emits": ["artifacts/generated_docs.json"],            },        ]    def _create_analysis_steps(        self, intent: TemplateIntent, patterns: dict[str, list[WorkflowPattern]]    ) -> list[dict[str, Any]]:        """Create steps for analysis workflows."""        return [            {                "id": "1.001",                "name": "Static Analysis",                "actor": "vscode_diagnostics",                "with": {                    "analyzers": self._get_analyzers_for_tech(intent.technologies),                    "focus": "comprehensive",                },                "emits": ["artifacts/static_analysis.json"],            },            {                "id": "1.002",                "name": "Code Review",                "actor": "ai_editor",                "with": {                    "goal": "Perform comprehensive code review and analysis",                    "files": "{{ inputs.files }}",                    "context": "code analysis",                },                "depends_on": ["1.001"],                "emits": ["artifacts/code_review.json"],            },        ]    def _create_generic_steps(        self, intent: TemplateIntent, patterns: dict[str, list[WorkflowPattern]]    ) -> list[dict[str, Any]]:        """Create generic steps for unknown workflow types."""        return [            {                "id": "1.001",                "name": "Analyze Files",                "actor": "vscode_diagnostics",                "with": {"analyzers": ["general"], "focus": "overview"},                "emits": ["artifacts/file_analysis.json"],            },            {                "id": "1.002",                "name": "Process Request",                "actor": "ai_editor",                "with": {                    "goal": "Process the user request",                    "files": "{{ inputs.files }}",                    "context": "general processing",                },                "depends_on": ["1.001"],                "emits": ["artifacts/processing_result.json"],            },        ]    def _get_analyzers_for_tech(self, technologies: list[str]) -> list[str]:        """Get appropriate analyzers for given technologies."""        analyzer_map = {            "python": ["python", "ruff", "mypy"],            "javascript": ["javascript", "eslint"],            "typescript": ["typescript", "tslint"],            "golang": ["go", "golint"],            "rust": ["rust", "clippy"],            "java": ["java", "spotbugs"],        }        analyzers = ["general"]        for tech in technologies:            if tech in analyzer_map:                analyzers.extend(analyzer_map[tech])        return list(set(analyzers))  # Remove duplicates    def _get_token_budget_for_complexity(self, complexity: str) -> int:        """Get appropriate token budget based on complexity."""        budget_map = {            "simple": 50000,            "medium": 120000,            "complex": 200000,            "enterprise": 300000,        }        return budget_map.get(complexity, 120000)    def _optimize_for_technologies(        self, template: dict[str, Any], technologies: list[str]    ):        """Add technology-specific optimizations to template."""        if "python" in technologies:            template["inputs"]["test_command"] = {"default": "pytest"}            template["inputs"]["lint_command"] = {"default": "ruff check ."}        elif "javascript" in technologies:            template["inputs"]["test_command"] = {"default": "npm test"}            template["inputs"]["lint_command"] = {"default": "eslint ."}        elif "typescript" in technologies:            template["inputs"]["test_command"] = {"default": "npm test"}            template["inputs"]["lint_command"] = {"default": "tslint ."}    def _save_template(self, template: dict[str, Any], template_name: str) -> Path:        """Save template to file system."""        template_path = self.templates_dir / f"{template_name}.yaml"        with open(template_path, "w", encoding="utf-8") as f:            yaml.dump(template, f, default_flow_style=False, sort_keys=False)        logger.info(f"Saved template: {template_path}")        return template_path    def list_templates(self) -> list[dict[str, Any]]:        """List all available templates."""        templates = []        for template_file in self.templates_dir.glob("*.yaml"):            try:                with open(template_file, encoding="utf-8") as f:                    template_data = yaml.safe_load(f)                templates.append(                    {                        "name": template_file.stem,                        "path": str(template_file),                        "description": template_data.get(                            "description", "No description"                        ),                        "metadata": template_data.get("metadata", {}),                    }                )            except Exception as e:                logger.warning(f"Failed to load template {template_file}: {e}")        return templates# CLI Integration functionsasync def smart_template_command(    request: str, template_name: str = None, save_path: str = None) -> dict[str, Any]:    """Generate smart template from natural language request."""    generator = SmartTemplateGenerator()    logger.info(f"Analyzing request: {request}")    result = await generator.generate_template_from_request(request, template_name)    logger.info(f"Generated template: {result['template_path']}")    logger.info(        f"Intent detected: {result['intent'].type} (confidence: {result['intent'].confidence:.2f})"    )    if save_path:        # Save to custom location        custom_path = Path(save_path)        custom_path.parent.mkdir(parents=True, exist_ok=True)        with open(custom_path, "w", encoding="utf-8") as f:            yaml.dump(result["template"], f, default_flow_style=False)        logger.info(f"Saved copy to: {custom_path}")    return resultdef list_templates_command() -> list[dict[str, Any]]:    """List all available templates."""    generator = SmartTemplateGenerator()    return generator.list_templates()# Example usagedef example_usage():    """Example of using the smart template system."""    import asyncio    async def run_examples():        # Generate templates for different scenarios        test_requests = [            "Fix authentication bug in user service",            "Add GraphQL API endpoints for product catalog",            "Implement comprehensive testing for payment module",            "Refactor legacy database access layer",            "Create documentation for REST API",        ]        for request in test_requests:            print(f"\n≡ƒºá Processing: {request}")            result = await smart_template_command(request)            print(f"Γ£à Generated: {Path(result['template_path']).name}")            print(                f"≡ƒô¥ Intent: {result['intent'].type} ({result['intent'].confidence:.2f})"            )    asyncio.run(run_examples())if __name__ == "__main__":    example_usage()